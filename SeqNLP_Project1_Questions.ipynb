{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqNLP_Project1_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunmp567/Deep-Learning-projects-and-code/blob/master/SeqNLP_Project1_Questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "outputId": "9883b67c-92aa-47c7-a1d5-6e8487f8bc87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCPC_WN-eCyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMEsHYrWxdtk",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0g381XzeCyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6n-uM2eCy2",
        "colab_type": "code",
        "outputId": "1b0624e6-8b02-415f-823b-4ba7d0fb3574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybtUgUReCy8",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OLM4eBeCy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxNDNhrseCzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# different activation functions such as tanh, relu , sigmoid were tried\n",
        "# SGD - different value for lr, decay were tried\n",
        "Initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "model.add(tf.keras.layers.Embedding(vocab_size+1, 64, input_length=maxlen))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid',kernel_initializer=Initializer))\n",
        "optimizer=tf.keras.optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofKqJBeOoBLj",
        "colab_type": "code",
        "outputId": "348adf34-f21d-4993-fc61-84697053fae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# the model was giving good accuracy in the beginning epocs and then accuracy flattened out\n",
        "# to 0.5 for many hyperparameter combinations , \n",
        "# so callback were introduced to store the weights and early checkpoints to stop the learning\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpoint = ModelCheckpoint(\"segmodel-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, \n",
        "                              mode=\"min\", period=1)\n",
        "stop = EarlyStopping(monitor=\"loss\", patience=2, mode=\"min\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3CSVVPPeCzD",
        "colab_type": "code",
        "outputId": "8687a6dd-0749-4bc1-828a-11491803ed40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=50,callbacks=[checkpoint,stop],verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "777/782 [============================>.] - ETA: 0s - loss: 1.3563 - accuracy: 0.5104\n",
            "Epoch 00001: saving model to segmodel-1.36.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.3554 - accuracy: 0.5106\n",
            "Epoch 2/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 1.1290 - accuracy: 0.5448\n",
            "Epoch 00002: saving model to segmodel-1.13.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.1282 - accuracy: 0.5450\n",
            "Epoch 3/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.9848 - accuracy: 0.5766\n",
            "Epoch 00003: saving model to segmodel-0.98.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.9835 - accuracy: 0.5771\n",
            "Epoch 4/50\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.8791 - accuracy: 0.6095\n",
            "Epoch 00004: saving model to segmodel-0.88.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.8787 - accuracy: 0.6094\n",
            "Epoch 5/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.7904 - accuracy: 0.6377\n",
            "Epoch 00005: saving model to segmodel-0.79.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.7904 - accuracy: 0.6378\n",
            "Epoch 6/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.7182 - accuracy: 0.6631\n",
            "Epoch 00006: saving model to segmodel-0.72.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.7179 - accuracy: 0.6632\n",
            "Epoch 7/50\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.6567 - accuracy: 0.6913\n",
            "Epoch 00007: saving model to segmodel-0.66.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6569 - accuracy: 0.6912\n",
            "Epoch 8/50\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.6058 - accuracy: 0.7153\n",
            "Epoch 00008: saving model to segmodel-0.61.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.6053 - accuracy: 0.7157\n",
            "Epoch 9/50\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.7366\n",
            "Epoch 00009: saving model to segmodel-0.56.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5592 - accuracy: 0.7364\n",
            "Epoch 10/50\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.7567\n",
            "Epoch 00010: saving model to segmodel-0.52.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5199 - accuracy: 0.7565\n",
            "Epoch 11/50\n",
            "773/782 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.7773\n",
            "Epoch 00011: saving model to segmodel-0.49.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4856 - accuracy: 0.7770\n",
            "Epoch 12/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.4533 - accuracy: 0.7956\n",
            "Epoch 00012: saving model to segmodel-0.45.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.7955\n",
            "Epoch 13/50\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.8117\n",
            "Epoch 00013: saving model to segmodel-0.43.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4257 - accuracy: 0.8115\n",
            "Epoch 14/50\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8293\n",
            "Epoch 00014: saving model to segmodel-0.40.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.4008 - accuracy: 0.8294\n",
            "Epoch 15/50\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8421\n",
            "Epoch 00015: saving model to segmodel-0.38.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3775 - accuracy: 0.8422\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.8560\n",
            "Epoch 00016: saving model to segmodel-0.36.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3575 - accuracy: 0.8560\n",
            "Epoch 17/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.3386 - accuracy: 0.8700\n",
            "Epoch 00017: saving model to segmodel-0.34.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3386 - accuracy: 0.8700\n",
            "Epoch 18/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.8786\n",
            "Epoch 00018: saving model to segmodel-0.32.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3223 - accuracy: 0.8785\n",
            "Epoch 19/50\n",
            "772/782 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.8883\n",
            "Epoch 00019: saving model to segmodel-0.31.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3067 - accuracy: 0.8882\n",
            "Epoch 20/50\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.2927 - accuracy: 0.8977\n",
            "Epoch 00020: saving model to segmodel-0.29.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2934 - accuracy: 0.8974\n",
            "Epoch 21/50\n",
            "772/782 [============================>.] - ETA: 0s - loss: 0.2792 - accuracy: 0.9075\n",
            "Epoch 00021: saving model to segmodel-0.28.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2793 - accuracy: 0.9074\n",
            "Epoch 22/50\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.9154\n",
            "Epoch 00022: saving model to segmodel-0.27.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2671 - accuracy: 0.9154\n",
            "Epoch 23/50\n",
            "769/782 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.9225\n",
            "Epoch 00023: saving model to segmodel-0.26.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2564 - accuracy: 0.9228\n",
            "Epoch 24/50\n",
            "771/782 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9294\n",
            "Epoch 00024: saving model to segmodel-0.25.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2463 - accuracy: 0.9295\n",
            "Epoch 25/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.9353\n",
            "Epoch 00025: saving model to segmodel-0.24.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2364 - accuracy: 0.9353\n",
            "Epoch 26/50\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.9411\n",
            "Epoch 00026: saving model to segmodel-0.23.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2280 - accuracy: 0.9410\n",
            "Epoch 27/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9440\n",
            "Epoch 00027: saving model to segmodel-0.22.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2201 - accuracy: 0.9440\n",
            "Epoch 28/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9494\n",
            "Epoch 00028: saving model to segmodel-0.21.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2119 - accuracy: 0.9494\n",
            "Epoch 29/50\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.9523\n",
            "Epoch 00029: saving model to segmodel-0.21.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2059 - accuracy: 0.9522\n",
            "Epoch 30/50\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.1986 - accuracy: 0.9562\n",
            "Epoch 00030: saving model to segmodel-0.20.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1986 - accuracy: 0.9562\n",
            "Epoch 31/50\n",
            "772/782 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9609\n",
            "Epoch 00031: saving model to segmodel-0.19.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1922 - accuracy: 0.9609\n",
            "Epoch 32/50\n",
            "772/782 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9636\n",
            "Epoch 00032: saving model to segmodel-0.19.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1863 - accuracy: 0.9638\n",
            "Epoch 33/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9677\n",
            "Epoch 00033: saving model to segmodel-0.18.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1809 - accuracy: 0.9676\n",
            "Epoch 34/50\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9691\n",
            "Epoch 00034: saving model to segmodel-0.18.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1755 - accuracy: 0.9690\n",
            "Epoch 35/50\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9728\n",
            "Epoch 00035: saving model to segmodel-0.17.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1703 - accuracy: 0.9729\n",
            "Epoch 36/50\n",
            "770/782 [============================>.] - ETA: 0s - loss: 0.1661 - accuracy: 0.9745\n",
            "Epoch 00036: saving model to segmodel-0.17.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1661 - accuracy: 0.9745\n",
            "Epoch 37/50\n",
            "773/782 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9771\n",
            "Epoch 00037: saving model to segmodel-0.16.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1620 - accuracy: 0.9770\n",
            "Epoch 38/50\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.1570 - accuracy: 0.9793\n",
            "Epoch 00038: saving model to segmodel-0.16.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1570 - accuracy: 0.9794\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.9794\n",
            "Epoch 00039: saving model to segmodel-0.15.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.9794\n",
            "Epoch 40/50\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.1494 - accuracy: 0.9817\n",
            "Epoch 00040: saving model to segmodel-0.15.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1497 - accuracy: 0.9816\n",
            "Epoch 41/50\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9833\n",
            "Epoch 00041: saving model to segmodel-0.15.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1460 - accuracy: 0.9832\n",
            "Epoch 42/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.9837\n",
            "Epoch 00042: saving model to segmodel-0.14.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1425 - accuracy: 0.9837\n",
            "Epoch 43/50\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 0.9852\n",
            "Epoch 00043: saving model to segmodel-0.14.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1395 - accuracy: 0.9852\n",
            "Epoch 44/50\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9857\n",
            "Epoch 00044: saving model to segmodel-0.14.h5\n",
            "782/782 [==============================] - 5s 6ms/step - loss: 0.1360 - accuracy: 0.9858\n",
            "Epoch 45/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9872\n",
            "Epoch 00045: saving model to segmodel-0.13.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1333 - accuracy: 0.9872\n",
            "Epoch 46/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9883\n",
            "Epoch 00046: saving model to segmodel-0.13.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1302 - accuracy: 0.9884\n",
            "Epoch 47/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9892\n",
            "Epoch 00047: saving model to segmodel-0.13.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1279 - accuracy: 0.9892\n",
            "Epoch 48/50\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9891\n",
            "Epoch 00048: saving model to segmodel-0.12.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1248 - accuracy: 0.9892\n",
            "Epoch 49/50\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9902\n",
            "Epoch 00049: saving model to segmodel-0.12.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1224 - accuracy: 0.9903\n",
            "Epoch 50/50\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9906\n",
            "Epoch 00050: saving model to segmodel-0.12.h5\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1203 - accuracy: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff120b66198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igq8Qm8GeCzG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AqOnLa2eCzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "extractor = tf.keras.Model(inputs=model.inputs,\n",
        "                        outputs=[layer.output for layer in model.layers])\n",
        "# Pass the index of the value to be retrieved in the x_test\n",
        "features = extractor.predict(x_test[100:101])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dUDSg7VeCzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9291978f-dd10-44c7-9ae9-c98331b5bd5d"
      },
      "source": [
        "print('embedding layer::',features[0])\n",
        "print('flatten layer::',features[1])\n",
        "print('dense layer layer::',features[2])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding layer:: [[[-0.00241878 -0.00198121 -0.02949657 ...  0.00719413 -0.0301381\n",
            "   -0.00125196]\n",
            "  [-0.00241878 -0.00198121 -0.02949657 ...  0.00719413 -0.0301381\n",
            "   -0.00125196]\n",
            "  [-0.00241878 -0.00198121 -0.02949657 ...  0.00719413 -0.0301381\n",
            "   -0.00125196]\n",
            "  ...\n",
            "  [ 0.01114866  0.01198614  0.00740292 ... -0.02444486  0.00656367\n",
            "   -0.0006521 ]\n",
            "  [-0.01190376  0.02656314  0.02684777 ... -0.01247837 -0.01696602\n",
            "    0.03347691]\n",
            "  [ 0.03468628  0.03626407  0.0078885  ... -0.02263929  0.05523968\n",
            "    0.05705073]]]\n",
            "flatten layer:: [[-0.00241878 -0.00198121 -0.02949657 ... -0.02263929  0.05523968\n",
            "   0.05705073]]\n",
            "dense layer layer:: [[0.00732397]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}